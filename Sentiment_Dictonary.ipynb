{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kopie von Sentiment_Dictonary.ipynb","provenance":[{"file_id":"1a8puCClhO7mmWy1AaVxFQZ6kG7_8h0vg","timestamp":1620899704601}],"collapsed_sections":[],"authorship_tag":"ABX9TyMghqdqDyksb4oeBXba8bj5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oKxgogqlHv_d","executionInfo":{"status":"ok","timestamp":1620899781269,"user_tz":-120,"elapsed":25013,"user":{"displayName":"Pascal Breuer","photoUrl":"","userId":"01908498179548227889"}},"outputId":"bdc436fa-fcde-46ac-c768-da10636fed51"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-OYZEZjIYh4","executionInfo":{"status":"ok","timestamp":1620899896237,"user_tz":-120,"elapsed":113598,"user":{"displayName":"Pascal Breuer","photoUrl":"","userId":"01908498179548227889"}},"outputId":"e921bd0b-d3f5-4aba-dbf6-f26c211ff2ab"},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","import re\n","import sklearn\n","import string\n","import nltk\n","from collections import Counter\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.naive_bayes import GaussianNB, ComplementNB, BernoulliNB, CategoricalNB, MultinomialNB\n","\n","from sklearn.metrics import accuracy_score\n","\n","nltk.download('stopwords')\n","\n","from sklearn.base import BaseEstimator, TransformerMixin\n","\n","\n","# Man kann auch mehrere hintereinander machen\n","\n","\n","class PreprocessorTransformer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, data, y=None):\n","        sentences = data['Sentence'].tolist()\n","        sentences = list((str(s) for s in sentences))\n","\n","        # muss vom generator object zurück zur liste gemacht werden\n","        sentences = list((s.lower() for s in sentences))\n","\n","        table = str.maketrans('', '', string.punctuation)\n","        sentences = [s.translate(table) for s in sentences]\n","\n","        sentences = [re.sub(r'\\d+', 'num', s) for s in sentences]\n","\n","        stopwords = set(nltk.corpus.stopwords.words('english'))\n","        sentences = [[word for word in s.split() if word not in stopwords] for s in sentences]\n","        return sentences\n","\n","\n","class BagOfWordsForEachSentenceTransformer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, sentences, y=None):\n","        print('transformed called')\n","        # Hier können wir dann unsere Sätze bearbeiten und zu numerischen Werten machen\n","        dics = []\n","\n","        # für jeden Satz wird ein Dictionary konstruiert\n","        for s in sentences:\n","\n","            c = Counter(s)\n","            dic = []\n","            for key in c:\n","                dic[key] = (c[key])\n","            dics.append(dic)\n","\n","        return (sentences, dics)\n","\n","\n","class BagOfWordsTransformer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self):\n","        # Kann man eventuell besser machen und muss man nicht so machen\n","        self.bigdict = {}\n","        self.training = True\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, sentences, y=None):\n","        if self.training:\n","            # Hier können wir dann unsere Sätze bearbeiten und zu numerischen Werten machen\n","            self.bigdict = {}\n","            for s in sentences:\n","                c = Counter(s)\n","                for key in c:\n","                    if key in self.bigdict:\n","                        self.bigdict[key] = self.bigdict[key] + c[key]\n","                    else:\n","                        self.bigdict[key] = 1\n","            self.training = False\n","\n","        return (sentences, self.bigdict)\n","\n","\n","class SentimentOpinionValueCalculatorTransformer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, value_file_name):\n","        df = pd.read_csv(value_file_name, sep=';')\n","        self.value_dict = pd.Series(df.value.values, index=df.word).to_dict()\n","        # for key in self.value_dict.keys():\n","        #     print(f'{key} - {self.value_dict[key]}')\n","        # print(f'unique values: {df.nunique()}')\n","        # print(self.value_dict)\n","        # print(len(self.value_dict))\n","        # d = {}\n","        # for word in df.word:\n","        #     d[word] = df.value[df.word == word]\n","        # for key in d.keys():\n","        #     print(f'{key} - {d[key]}')\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, sentences_and_dict):\n","        sentiment_opinion_scores = []\n","        sentences, d = sentences_and_dict\n","        for sentence in sentences:\n","            word_count = len(sentence)\n","            # print(f'length of sentence {sentence} = {word_count}')\n","            sentiment_opinion_score = 0\n","            if word_count > 0:\n","                for word in sentence:\n","                    if word in self.value_dict:\n","                        sentiment_opinion_score = sentiment_opinion_score + self.value_dict[word]\n","                sentiment_opinion_score = sentiment_opinion_score / word_count\n","            sentiment_opinion_scores.append([sentiment_opinion_score])\n","        return (sentences, d, sentiment_opinion_scores)\n","\n","\n","class SentimentOpinionValueCalculatorSingleValueTransformer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, value_file_name):\n","        df = pd.read_csv(value_file_name, sep=';')\n","        self.value_dict = pd.Series(df.value.values, index=df.word).to_dict()\n","        # for key in self.value_dict.keys():\n","        #     print(f'{key} - {self.value_dict[key]}')\n","        # print(f'unique values: {df.nunique()}')\n","        # print(self.value_dict)\n","        # print(len(self.value_dict))\n","        # d = {}\n","        # for word in df.word:\n","        #     d[word] = df.value[df.word == word]\n","        # for key in d.keys():\n","        #     print(f'{key} - {d[key]}')\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, sentences_and_dict):\n","        sentiment_opinion_scores = []\n","        sentences = sentences_and_dict\n","        for sentence in sentences:\n","            word_count = len(sentence)\n","            # print(f'length of sentence {sentence} = {word_count}')\n","            sentiment_opinion_score = 0\n","            if word_count > 0:\n","                for word in sentence:\n","                    if word in self.value_dict:\n","                        sentiment_opinion_score = sentiment_opinion_score + self.value_dict[word]\n","                sentiment_opinion_score = sentiment_opinion_score / word_count\n","            sentiment_opinion_scores.append([sentiment_opinion_score])\n","        return sentiment_opinion_scores\n","\n","\n","class SentimentOpinionValueCounterTransformer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, value_file_name):\n","        df = pd.read_csv(value_file_name, sep=';')\n","        self.value_dict = pd.Series(df.value.values, index=df.word).to_dict()\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, sentences_and_dict):\n","        sentiment_opinion_scores = []\n","        sentences = sentences_and_dict\n","        for sentence in sentences:\n","            word_count = len(sentence)\n","            # print(f'length of sentence {sentence} = {word_count}')\n","            sentiment_opinion_score = 0\n","            if word_count > 0:\n","                for word in sentence:\n","                    if word in self.value_dict:\n","                        sentiment_opinion_score += 1\n","                # sentiment_opinion_score = sentiment_opinion_score / word_count\n","            sentiment_opinion_scores.append([sentiment_opinion_score])\n","        return sentiment_opinion_scores\n","\n","\n","class SentenceToVectorTransformer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        print('Vec Trans  fit called')\n","        return self\n","\n","    def transform(self, sentence_dict_tuple, y=None):\n","        print('Vec Trans trans called')\n","        # Hier können wir dann unsere Sätze bearbeiten und zu numerischen Werten machen\n","\n","        # Tupel zerlegen\n","        sentence_fragments, dicts, sentiment_val_list = sentence_dict_tuple\n","        sorted_keys = [key for key in dicts.keys()]\n","        retval = []\n","        for sentence_fragment in sentence_fragments:\n","            vec = []\n","            for key in sorted_keys:\n","                if key in sentence_fragment:\n","                    vec.append(1)\n","                else:\n","                    vec.append(0)\n","            retval.append(vec)\n","        for index in range(len(sentiment_val_list)):\n","            # print(f'adding sentiment_val {sentiment_val_list[index]}')\n","            retval[index].append(int(sentiment_val_list[index][0]))\n","        print('added all sentiment_vals')\n","        return retval\n","\n","\n","def fit_and_predict_and_calculate_accuracy_pipe(pipe, train_input, train_ouput, test_input, test_output):\n","    pipe.fit(train_input, train_ouput)\n","\n","    y_pred_pipe = pipe.predict(test_input)\n","\n","    return accuracy_score(y_pred_pipe, test_output)\n","\n","\n","\n","dir_path = '/content/gdrive/MyDrive/Praxisprojekt/'\n","dict_file = dir_path + 'AFINN-both-abs.csv'\n","# dict_file = dir_path + '/sentiment_dict.csv'\n","\n","test_file = dir_path + 'Trainingdata_train.xlsx'\n","data_fit = pd.read_excel(test_file, sheet_name='sentences')\n","data_fit.drop(['SUBJindl', 'SUBJsrce', 'SUBJrhet', 'SUBJster', 'SUBJspee', 'SUBJinspe', 'SUBJprop', 'SUBJpolit'],\n","              axis=1,\n","              inplace=True)\n","\n","y_opin = data_fit.SUBJopin.to_numpy()\n","y_lang = data_fit.SUBJlang.to_numpy()\n","\n","test_file = dir_path + 'Trainingdata_test.xlsx'\n","data_test = pd.read_excel(test_file, sheet_name='sentences')\n","data_test.drop(['SUBJindl', 'SUBJsrce', 'SUBJrhet', 'SUBJster', 'SUBJspee', 'SUBJinspe', 'SUBJprop', 'SUBJpolit'],\n","                axis=1, inplace=True)\n","\n","\n","y_opin_test = data_test.SUBJopin.to_numpy()\n","y_lang_test = data_test.SUBJlang.to_numpy()\n","\n","\n","Cs = np.logspace(-6, -1, 10)\n","l1_ratio = np.random.uniform(size=20)\n","penalty = ['l1', 'l2', 'elasticnet']\n","solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n","\n","log_reg = sklearn.linear_model.LogisticRegression()\n","clf_log_reg_sentiment_dict = GridSearchCV(estimator=log_reg,\n","                                          param_grid=dict(C=Cs, penalty=penalty, solver=solver, l1_ratio=l1_ratio),\n","                                          n_jobs=-1, scoring='accuracy', verbose=0)\n","\n","pipe_log_reg_sentiment_dict = sklearn.pipeline.make_pipeline(PreprocessorTransformer(),\n","                                                              SentimentOpinionValueCalculatorSingleValueTransformer(dict_file),\n","                                                              # SentimentOpinionValueCounterTransformer(dict_file),\n","                                                              clf_log_reg_sentiment_dict)\n","\n","gnb2 = GaussianNB()\n","clf_gaussian_nb_sentiment_dict = GridSearchCV(estimator=gnb2, param_grid=dict(var_smoothing=Cs), n_jobs=-1,\n","                                              scoring='accuracy')\n","\n","pipe_gaussian_nb_sentiment_dict = sklearn.pipeline.make_pipeline(PreprocessorTransformer(),\n","                                                                  SentimentOpinionValueCalculatorSingleValueTransformer( dict_file),\n","                                                                  # SentimentOpinionValueCounterTransformer(dict_file),\n","                                                                  clf_gaussian_nb_sentiment_dict)\n","\n","cnb = ComplementNB()\n","clf_complement_nb_sentiment_dict = GridSearchCV(estimator=cnb, param_grid=dict(alpha=Cs), n_jobs=-1,\n","                                                scoring='accuracy')\n","\n","pipe_complement_nb_sentiment_dict = sklearn.pipeline.make_pipeline(PreprocessorTransformer(),\n","                                                                    SentimentOpinionValueCalculatorSingleValueTransformer(dict_file),\n","                                                                    # SentimentOpinionValueCounterTransformer(dict_file),\n","                                                                    clf_complement_nb_sentiment_dict)\n","\n","mnb = MultinomialNB()\n","clf_multinomial_nb_sentiment_dict = GridSearchCV(estimator=mnb, param_grid=dict(alpha=Cs), n_jobs=-1,\n","                                                  scoring='accuracy')\n","\n","pipe_multinomial_nb_sentiment_dict = sklearn.pipeline.make_pipeline(PreprocessorTransformer(),\n","                                                                    SentimentOpinionValueCalculatorSingleValueTransformer(dict_file),\n","                                                                    # SentimentOpinionValueCounterTransformer(dict_file),\n","                                                                    clf_multinomial_nb_sentiment_dict)\n","\n","bnb = BernoulliNB()\n","clf_bernoulli_nb_sentiment_dict = GridSearchCV(estimator=bnb, param_grid=dict(alpha=Cs, binarize=Cs), n_jobs=-1,\n","                                                scoring='accuracy')\n","\n","pipe_bernoulli_nb_sentiment_dict = sklearn.pipeline.make_pipeline(PreprocessorTransformer(),\n","                                                                  SentimentOpinionValueCalculatorSingleValueTransformer(dict_file),\n","                                                                  # SentimentOpinionValueCounterTransformer(dict_file),\n","                                                                  clf_bernoulli_nb_sentiment_dict)\n","\n","print('Results for Sentiment-dict:')\n","\n","y_test = y_lang_test\n","y_fit = y_lang\n","\n","accuracy_log_reg_sentiment_dict = fit_and_predict_and_calculate_accuracy_pipe(pipe_log_reg_sentiment_dict,\n","                                                                              data_fit, y_fit, data_test, y_test)\n","print(f'Accuracy Logistic Regression for Sentiment-dict: {accuracy_log_reg_sentiment_dict}')\n","\n","accuracy_gaussian_nb_sentiment_dict = fit_and_predict_and_calculate_accuracy_pipe(pipe_gaussian_nb_sentiment_dict,\n","                                                                                  data_fit, y_fit, data_test,\n","                                                                                  y_test)\n","print(f'Accuracy Gaussian Navie Bayes for Sentiment-dict: {accuracy_gaussian_nb_sentiment_dict}')\n","\n","accuracy_complement_nb_sentiment_dict = fit_and_predict_and_calculate_accuracy_pipe(\n","    pipe_complement_nb_sentiment_dict,\n","    data_fit, y_fit, data_test, y_test)\n","print(f'Accuracy Complement Navie Bayes for Sentiment-dict: {accuracy_complement_nb_sentiment_dict}')\n","\n","accuracy_multinomial_nb_sentiment_dict = fit_and_predict_and_calculate_accuracy_pipe(\n","    pipe_multinomial_nb_sentiment_dict,\n","    data_fit, y_fit, data_test, y_test)\n","print(f'Accuracy Multinomial Navie Bayes for Sentiment-dict: {accuracy_multinomial_nb_sentiment_dict}')\n","\n","accuracy_bernoulli_nb_sentiment_dict = fit_and_predict_and_calculate_accuracy_pipe(pipe_bernoulli_nb_sentiment_dict,\n","                                                                                    data_fit, y_fit, data_test,\n","                                                                                    y_test)\n","print(f'Accuracy Bernoulie Navie Bayes for Sentiment-dict: {accuracy_bernoulli_nb_sentiment_dict}')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Results for Sentiment-dict:\n","Accuracy Logistic Regression for Sentiment-dict: 0.6171875\n","Accuracy Gaussian Navie Bayes for Sentiment-dict: 0.625\n","Accuracy Complement Navie Bayes for Sentiment-dict: 0.267578125\n","Accuracy Multinomial Navie Bayes for Sentiment-dict: 0.611328125\n","Accuracy Bernoulie Navie Bayes for Sentiment-dict: 0.611328125\n"],"name":"stdout"}]}]}