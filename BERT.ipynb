{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPIkgjSMsUI6U7E3T5azOX/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"9xnDzF5FaaLq"},"source":["pip install transformers\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XtYTMD9ca0vZ"},"source":["from transformers import pipeline \n","print(pipeline('sentiment-analysis')('we love you'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3B0iJ5qxbgTR","executionInfo":{"status":"ok","timestamp":1620819697560,"user_tz":-120,"elapsed":20191,"user":{"displayName":"Clonker Habkeinen","photoUrl":"","userId":"01458166247648179716"}},"outputId":"aae5daa9-1002-4562-f2af-bf805eed429a"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q1InADgf5xm2"},"source":["import transformers as ppb\n","import pandas as pd\n","import numpy as np\n","import torch\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","\n","data = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/Trainingdata.xlsx', sheet_name = 'sentences')\n","\n","#id 2257 ist doof\n","#delete later\n","data = data.head(2257)\n","\n","data.drop(['SUBJindl', 'SUBJsrce', 'SUBJrhet', 'SUBJster', 'SUBJspee', 'SUBJinspe', 'SUBJprop', 'SUBJpolit'], axis=1, inplace=True)\n","\n","model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n","\n","# Load pretrained model/tokenizer\n","tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)\n","\n","#S채tze zerst체ckeln lassen\n","tokenized = data['Sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n","\n","#Padding hinzuf체gen \n","max_len = 0\n","for i in tokenized.values:\n","    if len(i) > max_len:\n","        max_len = len(i)\n","\n","padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n","\n","#Maske erstellen, um das Padding bei der Verarbeitung zu filtern\n","mask = np.where(padded != 0, 1, 0)\n","mask.shape\n","\n","#mache padded Array und Maske zu einem Tensor\n","#Tensor = irgendeine mehrdimensionale Matrix-Repr채sentation\n","input = torch.tensor(padded)  \n","mask = torch.tensor(mask)\n","\n","#gib unser Zeug an BERT\n","#no_grad = Angabe zur Simplifikation des Rechenvorgangs\n","with torch.no_grad():\n","    output = model(input, attention_mask=mask)\n","\n","#nur die erste Spalte auslesen = von BERT geschriebene Kennwerte\n","features = output[0][:,0,:].numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7R5pb9oNpMgh","executionInfo":{"status":"ok","timestamp":1620829856270,"user_tz":-120,"elapsed":2545,"user":{"displayName":"Clonker Habkeinen","photoUrl":"","userId":"01458166247648179716"}},"outputId":"9566c847-5f9a-45e8-975c-2a608f9ecb5a"},"source":["from sklearn.naive_bayes import GaussianNB\n","\n","#labels holen\n","labels = data[['SUBJlang', 'SUBJopin']]\n","\n","label1 = labels['SUBJlang']\n","label2 = labels['SUBJopin']\n","\n","#und jetzt alles durch die Toolbox von Scikit jagen\n","train_features, test_features, train_labels, test_labels = train_test_split(features, label1)\n","\n","lr_clf = LogisticRegression()\n","lr_clf.fit(train_features, train_labels)\n","\n","#Score\n","print(\"Score SUBJlang\")\n","print(lr_clf.score(test_features, test_labels))\n","\n","#und jetzt NOCHMAL alles durch die Toolbox von Scikit jagen\n","train_features, test_features, train_labels, test_labels = train_test_split(features, label2)\n","\n","lr_clf = LogisticRegression()\n","lr_clf.fit(train_features, train_labels)\n","\n","#Score 2\n","print(\"Score SUBJopin\")\n","print(lr_clf.score(test_features, test_labels))\n","\n","#und JETZT Naive Bayes\n","\n","train_features, test_features, train_labels, test_labels = train_test_split(features, label1)\n","\n","nb_clf = GaussianNB()\n","nb_clf.fit(train_features, train_labels)\n","\n","print(\"Score: Naive Bayes\")\n","print(\"SUBJlang\")\n","print(nb_clf.score(test_features, test_labels))\n","\n","train_features, test_features, train_labels, test_labels = train_test_split(features, label2)\n","\n","nb_clf = GaussianNB()\n","nb_clf.fit(train_features, train_labels)\n","\n","print(\"SUBJopin\")\n","print(nb_clf.score(test_features, test_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"stream","text":["Score SUBJlang\n","0.6070796460176991\n","Score SUBJopin\n","0.7256637168141593\n","Score: Naive Bayes\n","SUBJlang\n","0.46017699115044247\n","SUBJopin\n","0.5451327433628319\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itpwYC8VaWM0","executionInfo":{"status":"ok","timestamp":1620820292953,"user_tz":-120,"elapsed":713,"user":{"displayName":"Clonker Habkeinen","photoUrl":"","userId":"01458166247648179716"}},"outputId":"23379ed9-f5ea-4e12-8b16-e9e213cf331b"},"source":["import pandas as pd\n","df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n","df = df.head(3)\n","print(df[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0    a stirring , funny and finally transporting re...\n","1    apparently reassembled from the cutting room f...\n","2    they presume their audience wo n't sit still f...\n","Name: 0, dtype: object\n"],"name":"stdout"}]}]}