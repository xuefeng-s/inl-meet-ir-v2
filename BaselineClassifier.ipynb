{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaselineClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BerVF1-DB8Mm",
        "yE7j6KIqlcla",
        "KwRhCCN0BbJ8",
        "q-YlA2X5C1O5"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy8ue3suU6tI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09421e5d-0059-4ede-bfe9-e18bad32d3bd"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BerVF1-DB8Mm"
      },
      "source": [
        "# Basline Classifier Vader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGZQGcZkCCF9",
        "outputId": "61b0e30a-06cc-4e13-cfea-41fadf3744c3"
      },
      "source": [
        "## gut für social media, twitter\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Datensätze vorbereiten\n",
        "#data_train = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/Trainingdata_train.xlsx', sheet_name = 'sentences')\n",
        "data_test = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/datasetSentimentSRF_test.xlsx', sheet_name = 'sentences')\n",
        "#sentences = data_train['Sentence'].tolist()\n",
        "sentences = data_test['Sentence'].tolist()\n",
        "sentences = list((str(s) for s in sentences))\n",
        "\n",
        "# vader sentiment intensity analyser erstellen\n",
        "analyser = SIA()\n",
        "\n",
        "# Datenframe mit den Sätzen und ihren sentiment values erstellen\n",
        "#df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_train['SUBJlang01']})\n",
        "df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01']})\n",
        "\n",
        "\n",
        "# für jeden Satz die vader sentiment scores berechnen\n",
        "df['neg'] = df['sentences'].apply(lambda x:analyser.polarity_scores(x)['neg'])\n",
        "df['neu'] = df['sentences'].apply(lambda x:analyser.polarity_scores(x)['neu'])\n",
        "df['pos'] = df['sentences'].apply(lambda x:analyser.polarity_scores(x)['pos'])\n",
        "df['compound'] = df['sentences'].apply(lambda x:analyser.polarity_scores(x)['compound'])\n",
        "\n",
        "\n",
        "# Ergebniswerte kategorisieren in 0 neutral und 1 sentimental\n",
        "# ab 75% neutral ist es 0, ansonsten 1\n",
        "df['sentiment value'] = 0\n",
        "df.loc[df.neu<0.75, 'sentiment value']=1\n",
        "df.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)\n",
        "\n",
        "# accuracy berechnen\n",
        "print(\"accuracy vader sentiment: {0}\" .format(accuracy_score(df['sentiment label'], df['sentiment value'])))\n",
        "print(\"precision vader sentiment: {0}\" .format(precision_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"recall vader sentiment: {0}\" .format(recall_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"f-score vader sentiment: {0}\" .format(f1_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "accuracy vader sentiment: 0.5062931384490459\n",
            "precision vader sentiment: 0.4989145954823242\n",
            "recall vader sentiment: 0.5062931384490459\n",
            "f-score vader sentiment: 0.4600813193227776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE7j6KIqlcla"
      },
      "source": [
        "# Baseline Classifier TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbLl05HRlhRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1255f699-9bc1-4a36-8bed-9c7a2d813f7c"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from textblob import Blobber\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "\n",
        "# Datensätze vorbereiten\n",
        "data_test = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/datasetSentimentSRF_test.xlsx', sheet_name = 'sentences')\n",
        "sentences = data_test['Sentence'].tolist()\n",
        "sentences = list((str(s) for s in sentences))\n",
        "\n",
        "# Datenframe mit den Sätzen und deren Sentiment- und Opinion-Werte erstellen \n",
        "#df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01'], \"opinion label\" : data_test['SUBJopin01']})\n",
        "df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01']})\n",
        "\n",
        "\n",
        "# TextBlob-Werte ausrechnen \n",
        "df['polarity'] = df['sentences'].apply(lambda x: TextBlob(x).sentiment[0])\n",
        "#df['subjectivity'] = df['sentences'].apply(lambda x: TextBlob(x).sentiment[1])\n",
        "\n",
        "## sentiment label, opinion label: 0 = neutral\n",
        "## polarity: 0 = neutral, sonst positiver oder negativer wert für Sentiment\n",
        "## subjectivity: 0 = objectiv (neutral), 1 = subjectiv\n",
        "## range von +- 25% für neutral bei sentiment, 50% bei opinion\n",
        "df['sentiment value'] = 0\n",
        "df.loc[df.polarity>0.25, 'sentiment value']=1\n",
        "df.loc[df.polarity<-0.25, 'sentiment value']=1\n",
        "#df['opinion value'] = 0\n",
        "#df.loc[df.subjectivity>0.50, 'opinion value']=1\n",
        "#df.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)\n",
        "\n",
        "# accuracy berechnen\n",
        "print(\"accuracy textblob sentiment: {0}\" .format(accuracy_score(df['sentiment label'], df['sentiment value'])))\n",
        "print(\"precision textblob sentiment: {0}\" .format(precision_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"recall textblob sentiment: {0}\" .format(recall_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"f-score textblob sentiment: {0}\" .format(f1_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "#print(\"----------------------------------------------------------\")\n",
        "#print(\"accuracy textblob opinion: {0}\" .format(accuracy_score(df['opinion label'], df['opinion value'])))\n",
        "#print(\"precision textblob opinion: {0}\" .format(precision_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "#print(\"recall textblob opinion: {0}\" .format(recall_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "#print(\"f-score textblob opinion: {0}\" .format(f1_score(df['opinion label'], df['opinion value'], average='weighted')))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy textblob sentiment: 0.534307754770605\n",
            "precision textblob sentiment: 0.5433299374844599\n",
            "recall textblob sentiment: 0.534307754770605\n",
            "f-score textblob sentiment: 0.4832762042130588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwRhCCN0BbJ8"
      },
      "source": [
        "# Baseline Classifier Pattern3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT0inqM5Sv4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "259427a9-7879-4791-895d-c1c2857e1ba2"
      },
      "source": [
        "!pip install pattern"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pattern\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/07/b0e61b6c818ed4b6145fe01d1c341223aa6cfbc3928538ad1f2b890924a3/Pattern-3.6.0.tar.gz (22.2MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pattern) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/26/a6bd68f13e0f38fbb643d6e497fc3462be83a0b6c4d43425c78bb51a7291/backports.csv-1.0.7-py2.py3-none-any.whl\n",
            "Collecting mysqlclient\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/df/59cd2fa5e48d0804d213bdcb1acb4d08c403b61c7ff7ed4dd4a6a2deb3f7/mysqlclient-2.0.3.tar.gz (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pattern) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pattern) (4.2.6)\n",
            "Collecting feedparser\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/21/faf1bac028662cc8adb2b5ef7a6f3999a765baa2835331df365289b0ca56/feedparser-6.0.2-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.6MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/f3/4fec7dabe8802ebec46141345bf714cd1fc7d93cb74ddde917e4b6d97d88/pdfminer.six-20201018-py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pattern) (3.2.5)\n",
            "Collecting python-docx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/a0/52729ce4aa026f31b74cc877be1d11e4ddeaa361dc7aebec148171644b33/python-docx-0.8.11.tar.gz (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 29.9MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/f9/e11f893dcabe6bc222a1442bf5e14f0322a2d363c92910ed41947078a35a/CherryPy-18.6.0-py2.py3-none-any.whl (419kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 32.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pattern) (2.23.0)\n",
            "Collecting sgmllib3k\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (2.4.0)\n",
            "Collecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet; python_version > \"3.0\" in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (1.15.0)\n",
            "Collecting zc.lockfile\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/2a/268389776288f0f26c7272c70c36c96dcc0bdb88ab6216ea18e19df1fadd/zc.lockfile-2.0-py2.py3-none-any.whl\n",
            "Collecting jaraco.collections\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1a/a0d6861d2aca6df92643c755966c8a60e40353e4c5e7a5c2f4e5ed733817/jaraco.collections-3.3.0-py3-none-any.whl\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/fd29409cced540facdd29abb986d988cb1f22c8170d10022ea73af77fa55/portend-2.7.1-py3-none-any.whl\n",
            "Collecting cheroot>=8.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/95/86fe6480af78fea7b0e7e1bf02e6acd4cb9e561ea200bd6d6e1398fe5426/cheroot-8.5.2-py2.py3-none-any.whl (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern) (8.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2020.12.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->pattern) (1.14.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy->pattern) (57.0.0)\n",
            "Collecting jaraco.classes\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/74/bee5fc11594974746535117546404678fc7b899476e769c3c55bc0cfaa02/jaraco.classes-3.2.1-py3-none-any.whl\n",
            "Collecting jaraco.text\n",
            "  Downloading https://files.pythonhosted.org/packages/c1/74/2a3c4835c079df16db8a9c50263eebb0125849fee5b16de353a059b7545d/jaraco.text-3.5.0-py3-none-any.whl\n",
            "Collecting tempora>=1.8\n",
            "  Downloading https://files.pythonhosted.org/packages/44/83/4d5c3de53bbc463f30ab6764e27bc2e8ed9b59736e8b40d95403ff802008/tempora-4.0.2-py3-none-any.whl\n",
            "Collecting jaraco.functools\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/da/e51e7b58c8fe132990edd1e3ef25bcd9801eb7f91d0f642ac7f8d97e4a36/jaraco.functools-3.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern) (2.20)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2018.9)\n",
            "Building wheels for collected packages: pattern, mysqlclient, python-docx, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-cp37-none-any.whl size=22332722 sha256=06e0ae1f8d56f061cd4c3e32fe87803463a9935c74517410763d6943f6fc5087\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/9a/0e/5fb1a603ed4e3aa8722a88e9cf4a82da7d1b63e3d2cc34bee5\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.0.3-cp37-cp37m-linux_x86_64.whl size=100108 sha256=e9de53d69c499917786acad3f0a055caada71f1f377df2fa6032ed55e4601c3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/ca/e8/ad4e7ce3df18bcd91c7d84dd28c7c08db491a2a2360efed363\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-cp37-none-any.whl size=184508 sha256=97b88b759a2388b9cdf5a38ef4833f5955d32b14dbbe8178dba9e7276079d95a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/f1/a7cb70b38633ae04e7fb963b1c70f63fd6fc01c075b8230adc\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp37-none-any.whl size=6067 sha256=662fcc7536c24e168244ee9efa42305fc65b2f62093f39e03ce58936f53406b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
            "Successfully built pattern mysqlclient python-docx sgmllib3k\n",
            "Installing collected packages: backports.csv, mysqlclient, sgmllib3k, feedparser, cryptography, pdfminer.six, python-docx, zc.lockfile, jaraco.classes, jaraco.functools, jaraco.text, jaraco.collections, tempora, portend, cheroot, cherrypy, pattern\n",
            "Successfully installed backports.csv-1.0.7 cheroot-8.5.2 cherrypy-18.6.0 cryptography-3.4.7 feedparser-6.0.2 jaraco.classes-3.2.1 jaraco.collections-3.3.0 jaraco.functools-3.3.0 jaraco.text-3.5.0 mysqlclient-2.0.3 pattern-3.6 pdfminer.six-20201018 portend-2.7.1 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-4.0.2 zc.lockfile-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "korT1nAvDUFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7046510-2402-4334-fe82-512e81582e3b"
      },
      "source": [
        "from pattern.en import sentiment\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Datensätze vorbereiten\n",
        "data_test = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/datasetSentimentSRF_test.xlsx', sheet_name = 'sentences')\n",
        "sentences = data_test['Sentence'].tolist()\n",
        "sentences = list((str(s) for s in sentences))\n",
        "\n",
        "# Datenframe mit den Sätzen und deren Sentiment- und Opinion-Werte erstellen \n",
        "#df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01'], \"opinion label\" : data_test['SUBJopin01']})\n",
        "df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01']})\n",
        "\n",
        "\n",
        "# pattern3 Werte ausrechnen\n",
        "df['sentiment'] = df['sentences'].apply(lambda x: sentiment(x)[0])\n",
        "#df['subjectivity'] = df['sentences'].apply(lambda x: sentiment(x)[1])\n",
        "\n",
        "\n",
        "# Erster Wert: sentiment 1 bis -1 für positiv bis negativ\n",
        "# Zweiter Wert: subjectivity 0 bis 1 für objectiv bis subjectiv\n",
        "df['sentiment value'] = 0\n",
        "df.loc[df.sentiment>0.25, 'sentiment value']=1\n",
        "df.loc[df.sentiment<-0.25, 'sentiment value']=1\n",
        "#df['opinion value'] = 0\n",
        "#df.loc[df.subjectivity>0.50, 'opinion value']=1\n",
        "#df.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)\n",
        "\n",
        "\n",
        "print(\"accuracy pattern3 sentiment: {0}\" .format(accuracy_score(df['sentiment label'], df['sentiment value'])))\n",
        "print(\"precision pattern3 sentiment: {0}\" .format(precision_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"recall pattern3 sentiment: {0}\" .format(recall_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"f-score pattern3 sentiment: {0}\" .format(f1_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "#print(\"----------------------------------------------------------\")\n",
        "#print(\"accuracy pattern3 opinion: {0}\" .format(accuracy_score(df['opinion label'], df['opinion value'])))\n",
        "#print(\"precision pattern3 opinion: {0}\" .format(precision_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "#print(\"recall pattern3 opinion: {0}\" .format(recall_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "#print(\"f-score pattern3 opinion: {0}\" .format(f1_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy pattern3 sentiment: 0.5347137637028014\n",
            "precision pattern3 sentiment: 0.5440439658101632\n",
            "recall pattern3 sentiment: 0.5347137637028014\n",
            "f-score pattern3 sentiment: 0.48357910190287395\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}