{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaselineClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BerVF1-DB8Mm",
        "yE7j6KIqlcla",
        "KwRhCCN0BbJ8"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy8ue3suU6tI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35caa9c9-2cd2-4911-bbe0-b147e826ef11"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BerVF1-DB8Mm"
      },
      "source": [
        "# Basline Classifier Vader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGZQGcZkCCF9",
        "outputId": "31bdc631-2338-4d4a-ab1f-785aaf5f60c0"
      },
      "source": [
        "## gut für social media, twitter\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Datensätze vorbereiten\n",
        "#data_train = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/Trainingdata_train.xlsx', sheet_name = 'sentences')\n",
        "data_test = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/Data_AllFour_test.xlsx', sheet_name = 'sentences')\n",
        "#sentences = data_train['Sentence'].tolist()\n",
        "sentences = data_test['Sentence'].tolist()\n",
        "sentences = list((str(s) for s in sentences))\n",
        "\n",
        "# vader sentiment intensity analyser erstellen\n",
        "analyser = SIA()\n",
        "\n",
        "# Datenframe mit den Sätzen und ihren sentiment values erstellen\n",
        "#df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_train['SUBJlang01']})\n",
        "df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01']})\n",
        "\n",
        "\n",
        "# für jeden Satz die vader sentiment scores berechnen\n",
        "df['neg'] = df['sentences'].apply(lambda x:analyser.polarity_scores(x)['neg'])\n",
        "df['neu'] = df['sentences'].apply(lambda x:analyser.polarity_scores(x)['neu'])\n",
        "df['pos'] = df['sentences'].apply(lambda x:analyser.polarity_scores(x)['pos'])\n",
        "df['compound'] = df['sentences'].apply(lambda x:analyser.polarity_scores(x)['compound'])\n",
        "\n",
        "\n",
        "# Ergebniswerte kategorisieren in 0 neutral und 1 sentimental\n",
        "# ab 75% neutral ist es 0, ansonsten 1\n",
        "df['sentiment value'] = 0\n",
        "df.loc[df.neu<0.75, 'sentiment value']=1\n",
        "df.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)\n",
        "\n",
        "# accuracy berechnen\n",
        "print(\"accuracy vader sentiment: {0}\" .format(accuracy_score(df['sentiment label'], df['sentiment value'])))\n",
        "print(\"precision vader sentiment: {0}\" .format(precision_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"recall vader sentiment: {0}\" .format(recall_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"f-score vader sentiment: {0}\" .format(f1_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy vader: 0.5479417670682731\n",
            "precision vader sentiment: 0.5221702337855841\n",
            "recall vader sentiment: 0.5479417670682731\n",
            "f-score vader sentiment: 0.5056537441376106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE7j6KIqlcla"
      },
      "source": [
        "# Baseline Classifier TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbLl05HRlhRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3293443-1d49-4c9f-b8d9-85c78d0576d7"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from textblob import Blobber\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "\n",
        "# Datensätze vorbereiten\n",
        "data_test = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/Data_AllFour_test.xlsx', sheet_name = 'sentences')\n",
        "sentences = data_test['Sentence'].tolist()\n",
        "sentences = list((str(s) for s in sentences))\n",
        "\n",
        "# Datenframe mit den Sätzen und deren Sentiment- und Opinion-Werte erstellen \n",
        "#df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01'], \"opinion label\" : data_test['SUBJopin01']})\n",
        "df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01']})\n",
        "\n",
        "\n",
        "# TextBlob-Werte ausrechnen \n",
        "df['polarity'] = df['sentences'].apply(lambda x: TextBlob(x).sentiment[0])\n",
        "#df['subjectivity'] = df['sentences'].apply(lambda x: TextBlob(x).sentiment[1])\n",
        "\n",
        "## sentiment label, opinion label: 0 = neutral\n",
        "## polarity: 0 = neutral, sonst positiver oder negativer wert für Sentiment\n",
        "## subjectivity: 0 = objectiv (neutral), 1 = subjectiv\n",
        "## range von +- 25% für neutral bei sentiment, 50% bei opinion\n",
        "df['sentiment value'] = 0\n",
        "df.loc[df.polarity>0.25, 'sentiment value']=1\n",
        "df.loc[df.polarity<-0.25, 'sentiment value']=1\n",
        "#df['opinion value'] = 0\n",
        "#df.loc[df.subjectivity>0.50, 'opinion value']=1\n",
        "#df.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)\n",
        "\n",
        "# accuracy berechnen\n",
        "print(\"accuracy textblob sentiment: {0}\" .format(accuracy_score(df['sentiment label'], df['sentiment value'])))\n",
        "print(\"precision textblob sentiment: {0}\" .format(precision_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"recall textblob sentiment: {0}\" .format(recall_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"f-score textblob sentiment: {0}\" .format(f1_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "#print(\"----------------------------------------------------------\")\n",
        "#print(\"accuracy textblob opinion: {0}\" .format(accuracy_score(df['opinion label'], df['opinion value'])))\n",
        "#print(\"precision textblob opinion: {0}\" .format(precision_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "#print(\"recall textblob opinion: {0}\" .format(recall_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "#print(\"f-score textblob opinion: {0}\" .format(f1_score(df['opinion label'], df['opinion value'], average='weighted')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy textblob sentiment: 0.5592369477911646\n",
            "precision textblob sentiment: 0.5353289265710292\n",
            "recall textblob sentiment: 0.5592369477911646\n",
            "f-score textblob sentiment: 0.5071882584997353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwRhCCN0BbJ8"
      },
      "source": [
        "# Baseline Classifier Pattern3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT0inqM5Sv4R"
      },
      "source": [
        "!pip install pattern"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "korT1nAvDUFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c99e79d-a6f2-456d-9121-2f172ee72db6"
      },
      "source": [
        "from pattern.en import sentiment\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Datensätze vorbereiten\n",
        "data_test = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/Data_AllFour_test.xlsx', sheet_name = 'sentences')\n",
        "sentences = data_test['Sentence'].tolist()\n",
        "sentences = list((str(s) for s in sentences))\n",
        "\n",
        "# Datenframe mit den Sätzen und deren Sentiment- und Opinion-Werte erstellen \n",
        "#df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01'], \"opinion label\" : data_test['SUBJopin01']})\n",
        "df = pd.DataFrame({\"sentences\" : sentences, \"sentiment label\" : data_test['SUBJlang01']})\n",
        "\n",
        "\n",
        "# pattern3 Werte ausrechnen\n",
        "df['sentiment'] = df['sentences'].apply(lambda x: sentiment(x)[0])\n",
        "#df['subjectivity'] = df['sentences'].apply(lambda x: sentiment(x)[1])\n",
        "\n",
        "\n",
        "# Erster Wert: sentiment 1 bis -1 für positiv bis negativ\n",
        "# Zweiter Wert: subjectivity 0 bis 1 für objectiv bis subjectiv\n",
        "df['sentiment value'] = 0\n",
        "df.loc[df.sentiment>0.25, 'sentiment value']=1\n",
        "df.loc[df.sentiment<-0.25, 'sentiment value']=1\n",
        "#df['opinion value'] = 0\n",
        "#df.loc[df.subjectivity>0.50, 'opinion value']=1\n",
        "#df.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)\n",
        "\n",
        "\n",
        "print(\"accuracy pattern3 sentiment: {0}\" .format(accuracy_score(df['sentiment label'], df['sentiment value'])))\n",
        "print(\"precision pattern3 sentiment: {0}\" .format(precision_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"recall pattern3 sentiment: {0}\" .format(recall_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "print(\"f-score pattern3 sentiment: {0}\" .format(f1_score(df['sentiment label'], df['sentiment value'], average='weighted')))\n",
        "#print(\"----------------------------------------------------------\")\n",
        "#print(\"accuracy pattern3 opinion: {0}\" .format(accuracy_score(df['opinion label'], df['opinion value'])))\n",
        "#print(\"precision pattern3 opinion: {0}\" .format(precision_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "#print(\"recall pattern3 opinion: {0}\" .format(recall_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "#print(\"f-score pattern3 opinion: {0}\" .format(f1_score(df['opinion label'], df['opinion value'], average='weighted')))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy pattern3 sentiment: 0.5599899598393574\n",
            "precision pattern3 sentiment: 0.5364913920353697\n",
            "recall pattern3 sentiment: 0.5599899598393574\n",
            "f-score pattern3 sentiment: 0.5079340857708774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-YlA2X5C1O5"
      },
      "source": [
        "# Datenset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9T0iHa8DDYx",
        "outputId": "18e16849-f001-4a9e-b187-371047f4dd2c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def onlyOneSentence(entry):\n",
        "  liste = nltk.sent_tokenize(str(entry))\n",
        "  if len(liste)>1:\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "data = pd.read_excel('/content/gdrive/MyDrive/Praxisprojekt/Data_AllFour0.xlsx', sheet_name = 'sentences')\n",
        "newData = pd.DataFrame({'Sentence':[\"This sentence is awesome\"], 'SUBJlang':[3], 'SUBJlang01':[1]})\n",
        "\n",
        "for ind in data.index:\n",
        "  if onlyOneSentence(data['Sentence'][ind]):\n",
        "    df = pd.DataFrame({'Sentence':[data['Sentence'][ind]], 'SUBJlang': [data['SUBJlang'][ind]], 'SUBJlang01':[data['SUBJlang01'][ind]]})\n",
        "    newData = newData.append(df , ignore_index=True)\n",
        "\n",
        "newData.to_excel('/content/gdrive/MyDrive/Praxisprojekt/output.xlsx')\n",
        "print(\"writing output finished\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "writing output finished\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}